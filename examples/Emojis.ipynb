{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a830a5-6900-47e1-92a7-e22ef489fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from controllable_nca.image.emoji_dataset import EmojiDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0db7a5-bfe0-4501-9382-0105a03d5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from einops import rearrange\n",
    "\n",
    "from controllable_nca.dataset import MultiClass2DDataset\n",
    "from controllable_nca.utils import load_emoji, rgb\n",
    "\n",
    "\n",
    "class EmojiDataset(MultiClass2DDataset):\n",
    "    # EMOJI = 'ðŸ¦ŽðŸ˜€ðŸ’¥'\n",
    "    EMOJI = \"ðŸ¦ŽðŸ˜€ðŸ‘ðŸ•¸ðŸŽ„\"\n",
    "\n",
    "    digits = [\n",
    "        \"0030\",  # 0\n",
    "        \"0031\",  # 1\n",
    "        \"0032\",  # 2\n",
    "        \"0033\",  # 3\n",
    "        \"0034\",  # 4\n",
    "        \"0035\",  # 5\n",
    "        \"0036\",  # 6\n",
    "        \"0037\",  # 7\n",
    "        \"0038\",  # 8\n",
    "        \"0039\",  # 9\n",
    "    ]\n",
    "\n",
    "    def __init__(self, image_size=64):\n",
    "        emojis = torch.stack(\n",
    "            [load_emoji(e, image_size) for e in EmojiDataset.EMOJI], dim=0\n",
    "        )\n",
    "        targets = torch.arange(emojis.size(0))\n",
    "        super(EmojiDataset, self).__init__(emojis, targets)\n",
    "        self.digits = torch.stack(\n",
    "            [load_emoji(None, image_size, code=e) for e in EmojiDataset.digits], dim=0\n",
    "        )\n",
    "\n",
    "    def visualize(self, idx=0):\n",
    "        self.plot_img(self.x[idx : idx + 1])\n",
    "\n",
    "    def plot_img(self, img):\n",
    "        with torch.no_grad():\n",
    "            rgb_image = rgb(img, False).squeeze().detach().cpu().numpy()\n",
    "        rgb_image = rearrange(rgb_image, \"c w h -> w h c\")\n",
    "        _ = plt.imshow(rgb_image)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152c3400-8285-4d32-80b4-6d023028a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EmojiDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ed5b0-0ee7-4e72-9b72-7fed066d989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.visualize(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191f4598-847c-4f77-9c73-823da0f46648",
   "metadata": {},
   "source": [
    "### Import NCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45141dc-b3b6-46c4-9b0d-fe92bf2616cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from controllable_nca.image.nca import ControllableImageNCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89d666-a508-4f76-9e24-ea9c28c18944",
   "metadata": {},
   "outputs": [],
   "source": [
    "nca =  ControllableImageNCA(target_shape=dataset.target_size(), living_channel_dim=3, num_hidden_channels=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b980d825-e7a1-4a45-b78e-23318ac56a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "nca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44856ea6-f166-48fb-aade-d2788575a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(dict((p.data_ptr(), p.numel()) for p in nca.parameters()).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6fc981-2336-4702-a659-69de09fea63c",
   "metadata": {},
   "source": [
    "### Put in Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a51afe8-e4e4-4c47-a520-b7bd30780ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "dataset.to(device)\n",
    "nca = nca.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe31da20-687c-46e6-ae54-be76ece5329e",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e316117-14cf-4bcf-b759-efc91ac10e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from controllable_nca.image.trainer import ControllableNCAImageTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed124d-a3a1-4040-b457-f230c9f3f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ControllableNCAImageTrainer(nca, dataset, nca_steps=[32, 48], lr=1e-3, num_damaged=0, damage_radius=3, device=device, pool_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead95232-774e-4048-abef-fef9827b75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(batch_size=5, epochs=50000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pycanvas] *",
   "language": "python",
   "name": "conda-env-pycanvas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
